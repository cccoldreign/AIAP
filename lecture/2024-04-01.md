# Библиотеки научных вычислений, анализа данных и машинного обучения в экосистеме Python

## NumPy


![numpy-logo](https://numpy.org/images/logo.svg)

Документация: [NumPy documentation — NumPy v1.26 Manual](https://numpy.org/doc/stable/)

Официальный сайт: https://numpy.org/

Страница библиотеки в PyPI: [numpy · PyPI](https://pypi.org/project/numpy/)

`pip install numpy`

Исходный код: [GitHub - numpy/numpy: The fundamental package for scientific computing with Python.](https://github.com/numpy/numpy)

- предоставляет поддержку многомерных массивов (и, разумеется, матриц)
- предназначена для работы с данными высоких размерностей и с большими объемами данных
- (частично) написана на C и C++, что обеспечивает высокую скорость и эффективный менеджмент памяти
- предоставляет свою систему типов, совместимую с типами C для гранулярной настройки потребления памяти и точности вычислений
- предоставляет связки с C, C++, Fortran (т.е. полезным, но все-таки легаси)
- содержит набор готовых функций для математических вычислений, включая операции над матрицами (и тензорами), линейную алгебру, функции распределения вероятности, преобразованья Фурье и т.п.
- добавляет в Питон поддержку честных массивов (через класс `ndarray`), что обеспечивает прирост производительности относительно встроенных списков до 50 раз
- высокая степень оптимизации (одна из основных целей разработки — минимизация потребления памяти)
- фундамент для всех популярных библиотек научных вычислений
- но! массивы требуют непрерывных блоков памяти, что иногда бывает проблемой из-за фрагментации, особенно в случае со стандартными типами данных Питона
- вводит понятие `NaN` (Not a Number), которое не является эквивалентом Питоновскому `None`, что в ряде случае может приводить к проблемам с совместимостью, т.к. в Питоне такой концепт в чистом виде отсутствует

## SciPy

![scipy-logo](https://scipy.org/images/logo.svg)

Документация: [SciPy documentation — SciPy v1.11.3 Manual](https://docs.scipy.org/doc/scipy/)
Официальный сайт: https://scipy.org/

Страница библиотеки в PyPI: [scipy · PyPI](https://pypi.org/project/scipy/)

`pip install scipy`

Исходный код: [GitHub - scipy/scipy: SciPy library main repository](https://github.com/scipy/scipy)

- построенная на базе NumPy библиотека научных и технических вычислений
- содержит методы и алгоритмы статистического анализа, алгебры, оптимизации, цифровой обработки сигналов, интерполяции, многомерных преобразований, вычислений в $n$-мерных пространствах, обработки изображений (в виде многомерных массивов), кластеризации, работы с разреженными матрицами и т.д., см. перечень подпакетов ([SciPy User Guide — SciPy v1.12.0 Manual](https://docs.scipy.org/doc/scipy/tutorial/index.html#subpackages))
- предоставляет возможности параллельных вычислений
- из коробки дает функции визуализации данных

## matplotlib

![matplotlib.org/\_static/logo\_dark.svg](https://matplotlib.org/_static/logo_dark.svg)

Документация: [API Reference — Matplotlib 3.8.3 documentation](https://matplotlib.org/stable/api/index)

Официальный сайт: https://matplotlib.org/

Страница библиотеки в PyPI: [matplotlib · PyPI](https://pypi.org/project/matplotlib/)

`pip install matplotlib`

Исходный код: [GitHub - matplotlib/matplotlib: matplotlib: plotting with Python](https://github.com/matplotlib/matplotlib)

- библиотека для научной визуализации: построения графиков, диаграмм, тепловых карт; в 2 и в 3 измерениях
- Гистограммы ![](https://matplotlib.org/stable/_images/sphx_glr_hist_plot_001.png)
- Круговые диаграммы ![](https://matplotlib.org/stable/_images/sphx_glr_pie_001.png)
- Ящики с усами ![](https://matplotlib.org/stable/_images/sphx_glr_boxplot_plot_001.png)
- Потоковые карты (streamplots) ![](https://matplotlib.org/stable/_images/sphx_glr_streamplot_001.png)
- График поверхности (surface plot) ![](https://matplotlib.org/stable/_images/sphx_glr_surface3d_simple_001.png)
- Позволяет визуализировать массивы данных при помощи заданного типа графика (что, например, открывает возможность вывода картинок на экран, если представить картинку как двумерный массив: ![](https://matplotlib.org/stable/_images/sphx_glr_image_clip_path_001.png)
- Есть возможность объединять множество графиков в одно изображение (т.е. строить витрины данных): ![](https://matplotlib.org/stable/_images/sphx_glr_multi_image_001.png)
- ![](https://matplotlib.org/stable/_images/sphx_glr_irregulardatagrid_001.png)
- Обширная галерея с примерами кода визуализации: [Examples — Matplotlib 3.8.3 documentation](https://matplotlib.org/stable/gallery/index.html)
- Легко встраивается в среды разработки (например, Jupyter Notebook)
- Легко экспортировать полученные изображения в нужном формате, разрешении и оформлении (что делает библиотеку незаменимой для оформления статей, отчетных работ, академических работ и т.п.)
- Многие названия методов схожи с Matlab
- Из минусов:
    - интерактивность страдает
    - нужно много кода для сложных графиков
    - комплексная витрина данных требует чрезмерных усилий (чаще проще найти стороннюю библиотеку)

## seaborn

![](https://seaborn.pydata.org/_static/logo-wide-lightbg.svg)


Документация: [User guide and tutorial — seaborn 0.13.0 documentation](https://seaborn.pydata.org/tutorial.html)

Официальный сайт: https://seaborn.pydata.org/

Страница библиотеки в PyPI: [seaborn · PyPI](https://pypi.org/project/seaborn/)

`pip install seaborn`

Исходный код: [GitHub - mwaskom/seaborn: Statistical data visualization in Python](https://github.com/mwaskom/seaborn)

- высокоуровневый набор методов и функций для matplotlib, расширяющий возможности по визуализации
- добавляет большое число видов графиков и предоставляет удобный интерфейс методов их построения
- (субъективно) предлагает более приятную цветовую палитру
- умеет работать сразу с структурами данных, что ускоряет визуализацию по сравнению с matplotlib
- проще сделать графики интерактивными (но все еще сложно!)
- поддерживает темы
- умеет визуализировать регрессионные модели и временные ряды
- хорошо стыкуется с датафреймами из Pandas

Галерея примеров: [Example gallery — seaborn 0.13.0 documentation](https://seaborn.pydata.org/examples/index.html)

Ящики с усами:

![](https://seaborn.pydata.org/_images/horizontal_boxplot.png)

Диаграмма рассеяния 

![](https://seaborn.pydata.org/_images/scatterplot_sizes.png)

Регрессия

![](https://seaborn.pydata.org/_images/multiple_regression.png)

Тепловая карта

![](https://seaborn.pydata.org/_images/spreadsheet_heatmap.png)

Временные ряды

![](https://seaborn.pydata.org/_images/timeseries_facets.png)

Комбинация линейной регрессии и распределений

![](https://seaborn.pydata.org/_images/regression_marginals.png)

```python
import seaborn as sns
sns.set_theme(style="darkgrid")

tips = sns.load_dataset("tips")
g = sns.jointplot(x="total_bill", y="tip", data=tips,
      kind="reg", truncate=False,
      xlim=(0, 60), ylim=(0, 12),
      color="m", height=7)
```

Радиальная проекция

![](https://seaborn.pydata.org/_images/radial_facets.png)

```python
import numpy as np
import pandas as pd
import seaborn as sns

sns.set_theme()

# Generate an example radial datast
r = np.linspace(0, 10, num=100)
df = pd.DataFrame({'r': r, 'slow': r, 'medium': 2 * r, 'fast': 4 * r})

# Convert the dataframe to long-form or "tidy" format
df = pd.melt(df, id_vars=['r'], var_name='speed', value_name='theta')

# Set up a grid of axes with a polar projection
g = sns.FacetGrid(df, col="speed", hue="speed",
                  subplot_kws=dict(projection='polar'), height=4.5, 
                  sharex=False, sharey=False, despine=False)

# Draw a scatterplot onto each axes in the grid
g.map(sns.scatterplot, "theta", "r")
```

Матрица корреляции

![](https://seaborn.pydata.org/_images/many_pairwise_correlations.png)

`ridge plot`

![](https://seaborn.pydata.org/_images/kde_ridgeplot.png)

![](https://seaborn.pydata.org/_images/joint_kde.png)

Иерархия + тепловая карта

![](https://seaborn.pydata.org/_images/structured_heatmap.png)

```python
import pandas as pd
import seaborn as sns
sns.set_theme()

# Load the brain networks example dataset
df = sns.load_dataset("brain_networks", header=[0, 1, 2], index_col=0)

# Select a subset of the networks
used_networks = [1, 5, 6, 7, 8, 12, 13, 17]
used_columns = (df.columns.get_level_values("network")
                          .astype(int)
                          .isin(used_networks))
df = df.loc[:, used_columns]

# Create a categorical palette to identify the networks
network_pal = sns.husl_palette(8, s=.45)
network_lut = dict(zip(map(str, used_networks), network_pal))

# Convert the palette to vectors that will be drawn on the side of the matrix
networks = df.columns.get_level_values("network")
network_colors = pd.Series(networks, index=df.columns).map(network_lut)

# Draw the full plot
g = sns.clustermap(df.corr(), center=0, cmap="vlag",
                   row_colors=network_colors, col_colors=network_colors,
                   dendrogram_ratio=(.1, .2),
                   cbar_pos=(.02, .32, .03, .2),
                   linewidths=.75, figsize=(12, 13))
```

## pandas

![pandas-logo](https://pandas.pydata.org/static/img/pandas.svg)

Документация: [pandas documentation — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/)

Официальный сайт: https://pandas.pydata.org/

Страница библиотеки в PyPI: [pandas · PyPI](https://pypi.org/project/pandas/)

`pip install pandas`

Исходный код: [GitHub - pandas-dev/pandas: Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more](https://github.com/pandas-dev/pandas)

Литература: https://e.lanbook.com/book/348086

Уэс Маккинни (автор pandas). *Python и анализ данных. Первичная обработка данных с применением pandas, NumPy и Jupiter*

Маккинни, У. Python и анализ данных. Первичная обработка данных с применением pandas, NumPy и Jupiter : справочник / У. Маккинни ; перевод с английского А. А. Слинкина. — 3-е изд. — Москва : ДМК Пресс, 2023. — 536 с. — ISBN 978-5-93700-174-0. — Текст : электронный // Лань : электронно-библиотечная система. — URL: https://e.lanbook.com/book/348086 (дата обращения: 16.11.2023). — Режим доступа: для авториз. пользователей.

Праймер в документации: [10 minutes to pandas — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/user_guide/10min.html)

- основное назначение библиотеки — работа с большими массивами данных
- готовые интеграции с наиболее распространенными форматами хранения и манипуляции данных, включая CSV, TSV, JSON, SQL, BigQuery, Excel [IO tools (text, CSV, HDF5, …) — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/user_guide/io.html)
- функционал включает просмотр данных, выборки, анализ аномалий, отсутствующих данных, слияние, группировку, реструктуризацию (reshaping, изменение числа измерений), временные ряды, категориальные данные и манипуляцию ими, визуализацию в виде графиков и диаграмм
- основными концепциями и объектами в pandas являются датафреймы (DataFrames) и серии/ряды (Series)

[Series — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/reference/series.html)

[DataFrame — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/reference/frame.html)

Датафрейм — двумерная структура данных, серия — одномерная структура данных.

Каждый датафрейм можно разбить на серии. Несколько серий можно объединить в датафрейм.

И датафрейм, и серия имеют индекс, который не является частью данных. Все объекты в pandas используют C-подобные типы (заимствованные из numpy и полагающиеся на их реализацию в той библиотеке).

Одним из больших преимуществ pandas является гранулярный контроль над типами данных на уровне серий (например, вы можете задать для колонки тип данных `int8`). Настоящее преимущество такого подхода раскрывается при использовании категориальных данных.

Категория — специальный ярлык, который соотносится с отдельной областью (массивом) в памяти, заменяя всех вхождения категории в датафрейме или серии на индекс этой категории в хранилище категорий.

Это позволяет заменять повторяющиеся, например, строковые данные на `int8`.

Подробнее о категориальных данных: [Categorical data — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/user_guide/categorical.html)

Всегда можно отслеживать потребление памяти ([pandas.Series.memory\_usage — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.memory_usage.html), [pandas.DataFrame.memory\_usage — pandas 2.1.3 documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.memory_usage.html))

- обеспечивает простое представление сложных структур данных: есть возможность агрегации данных из разных источников, с разными типами, с разной полнотой и удобный инструмент для изучения (explore), анализа, манипуляции и визуализации
- все необходимые методы уже включены в библиотеку, т.е. она предлагает полный цикл анализа данных
- легко масштабируется под задачи, готова к работе с большими данными

Из минусов:

- easy to learn, hard to master, пользоваться можно начать относительно легко, но продвинутые функции и методы использования библиотеки требуют отдельного изучения
- документация не всегда успевает за библиотекой, требует понимания, что именно и для каких целей вы ищете
- несовместима с тензорами и иными структурами высоких размерностей: несмотря на то, что построена на базе numpy, многомерные массивы гораздо лучше обрабатываются в самой numpy, т.к. датафреймы и серии — дву- и одномерные структуры данных

```python
df = pd.DataFrame([[1, 2], [4, 5], [7, 8]], 
    index=['cobra', 'viper', 'sidewinder'],
    columns=['max_speed', 'shield'])

# out:
                max_speed  shield
    cobra               1       2
    viper               4       5
    sidewinder          7       8
```

```python
df.loc[df['shield'] > 6]

#out:
            max_speed  shield
sidewinder          7       8
```

```python
mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},
          {'a': 100, 'b': 200, 'c': 300, 'd': 400},
          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]

df = pd.DataFrame(mydict)

df
      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000

df.iloc[:3]

      a     b     c     d
0     1     2     3     4
1   100   200   300   400
2  1000  2000  3000  4000

df.iloc[1:3, 0:3]
      a     b     c
1   100   200   300
2  1000  2000  3000

df.iloc[:, lambda df: [0, 2]]
      a     c
0     1     3
1   100   300
2  1000  3000
```

```python
df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])

df
   A  B
0  4  9
1  4  9
2  4  9

df.apply(np.sqrt)
     A    B
0  2.0  3.0
1  2.0  3.0
2  2.0  3.0

df.apply(np.sum, axis=0)
A    12
B    27
dtype: int64

df.apply(np.sum, axis=1)
0    13
1    13
2    13
dtype: int64

df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)
   foo  bar
0    1    2
1    1    2
2    1    2
```

```python
df = pd.DataFrame({'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'], 'Max Speed': [380., 370., 24., 26.]})

df
   Animal  Max Speed
0  Falcon      380.0
1  Falcon      370.0
2  Parrot       24.0
3  Parrot       26.0

df.groupby(['Animal']).mean()
        Max Speed
Animal
Falcon      375.0
Parrot       25.0

df = pd.DataFrame({'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'], 'Max Speed': [380., 370., 24., 26.]})

df.groupby("Animal", group_keys=True).apply(lambda x: x)
          Animal  Max Speed
Animal
Falcon 0  Falcon      380.0
       1  Falcon      370.0
Parrot 2  Parrot       24.0
       3  Parrot       26.0
```

## scikit-learn

![sklearn-logo](https://raw.githubusercontent.com/scikit-learn/scikit-learn/e84a4c2935e9531c574e61cfce840e53866f6546/doc/logos/scikit-learn-logo-without-subtitle.svg)

Документация: [User guide: contents — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/user_guide.html)

Официальный сайт: https://scikit-learn.org/

Страница библиотеки в PyPI: [scikit-learn · PyPI](https://pypi.org/project/scikit-learn/)

`pip install scikit-learn`

Исходный код: [GitHub - scikit-learn/scikit-learn: scikit-learn: machine learning in Python](https://github.com/scikit-learn/scikit-learn)

Наиболее популярная в отрыве от каких-либо отдельных направлений развития машинного обучения библиотека Python для соответствующих моделей.

- содержит реализации большинства популярных алгоритмов регрессии, классификации, кластеризации
- включает также методы снижения размерности (например, метод главных компонент, PCA `Principal component analysis`), различные алгоритмы предварительной обработки данных (препроцессинга) — нормализация, детекция аномалий, очистка данных и т.п., интерфейс подбора моделей (т.е. тестирование нескольких моделей с возможностью выбора наилучшей для задачи)
- включает в себя множество классических датасетов для демонстрации и обучения (например, Ирисы Фишера и т.д.)
- пермиссивная (разрешающая) лицензия BSD и открытый исходный код — можно свободно использовать все модели и алгоритмы в любых (в том числе коммерческих) проектах

Из минусов:

- не подходит для deep learning (глубокого обучения), нужно использовать более специализированные инструменты
- в последнее время выявились проблемы масштабирования (по-настоящему большие датасеты сложно обрабатывать, не хватает инструментария для эффективного скейлинга)
- нет возможности легко перевести данные из датафрейма pandas в вид, пригодный для модели из scikit-learn — придется использовать в качестве промежуточных структур ndarray из NumPy

### Структура и основные модели и алгоритмы библиотеки

1. Обучение с учителем (Supervised learning) [1. Supervised learning — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/supervised_learning.html)
2. Обучение без учителя (Unsupervised learning) [2. Unsupervised learning — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/unsupervised_learning.html)
3. Выбор моделей и их оценка
4. Инспекция данных
5. Визуализация данных
6. Преобразования данных
7. Инструменты загрузки готовых датасетов

Больший плюс документации — есть возможность скачать примеры как в виде .py-файла ([plot\_adaboost\_regression.py](https://scikit-learn.org/stable/_downloads/2da78c80da33b4e0d313b0a90b923ec8/plot_adaboost_regression.py)), так и в виде Jupyter-ноутбука ([plot\_adaboost\_regression.ipynb](https://scikit-learn.org/stable/_downloads/38e826c9e3778d7de78b2fc671fd7903/plot_adaboost_regression.ipynb)). Весь пример реализации такого алгоритма, включая исходные данные, доступен для изучения и экспериментов.

# Лабораторная работа №4. Научные вычисления на Python

1. Предоставлен набор данных — наблюдения за погодой. Данные включают в себя время, описание, тип осадков, температуру, ощущаемую температуру, влажность, скорость ветра, направление ветра, видимость, давление.
2. Загрузить данные в DataFrame при помощи библиотеки `pandas`. Проследить за корректными `dtypes (df.info())`
3. Построить регрессионную модель, которая принимает на вход сведения о температуре и влажности, выдает ощущаемую температуру. Для этого использовать класс `LinearRegression` из `Scikit-learn`. При обучении модели использовать `train_test_split` из `Scikit-learn`
4. Необходимо визуализировать данные по каждой паре параметров и линию регрессии при помощи диаграммы рассеяния. Использовать `seaborn` при построении диаграмм (например, [https://seaborn.pydata.org/generated/seaborn.pairplot.html)](https://seaborn.pydata.org/generated/seaborn.pairplot.html))
5. Усложнить модель, добавив большее число параметров, например, параметр скорости ветра. На выходе по-прежнему дать ощущаемую температуру.
6. Собрать веб-интерфейс: вывести визуализацию модели, организовать пользовательский интерфейс при помощи HTML-форм. Пользователь вводит температуру, сведения о влажности и иные параметры модели, получает ощущаемую температуру. Можно брать любой фреймворк, например, Flask.

Лабораторная работа оценивается выше, если модель построена на своих данных, например, о погоде в Перми или Пермском крае.